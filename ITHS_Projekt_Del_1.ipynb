{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this lab, I want to predict whether the value of a stock will go up or down. For this reason, I will use Random Forest Classification rather than Regression (which would be used for trying to predict the actual value)\n",
    "\n",
    "# install pip yfinance (if not installed already :))\n",
    "#! pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance library which contains historical data for stocks\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import other relevant libraries and modules needed for this lab\n",
    "import pandas as pd # for data manipulation and analysis\n",
    "import matplotlib.pyplot as plt # for data visualisation - plots, graphs & charts\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier # module that includes two randomised decision tree algorithms; Random Forest & Extra Trees Method (we're just using Random Forest now)\n",
    "from sklearn.metrics import precision_score # module for calculating the precision score (observations that the model correctly predicted out of all predictions made)\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the ticker for the specific stock we want to predict (in this case it's Amazon)\n",
    "amazon = yf.Ticker(\"AMZN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the historical data for this ticker and store to the variable\n",
    "amazon  = amazon.history(period=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create extra columns in order to calculate the incidences where the value went up (represented by 1). Otherwise it's 0.\n",
    "\n",
    "# \"Tomorrow\" aligns the closing value of the current day with the open prices of the following day\n",
    "amazon[\"Tomorrow\"] = amazon[\"Close\"].shift(-1)\n",
    "\n",
    "# \"Target\" returns 1 if the value increased, 0 if it didn't increase\n",
    "amazon[\"Target\"] = (amazon[\"Tomorrow\"]> amazon[\"Close\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open            0\n",
       "High            0\n",
       "Low             0\n",
       "Close           0\n",
       "Volume          0\n",
       "Dividends       0\n",
       "Stock Splits    0\n",
       "Tomorrow        1\n",
       "Target          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the data coming in from yfinance is real-time and is already cleaned, but we can check our new columns for null values (there is only one in the  'Tomorrow' column)\n",
    "amazon.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(min_samples_split=100, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(min_samples_split=100, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(min_samples_split=100, random_state=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start creating our model and defining our train and test datasets\n",
    "\n",
    "# defining the n_estimators value means tuning our parameters aka the number of trees we want to build. The higher the better, but the slower the model\n",
    "# min_samples_split evaluates the number of samples in the node. if the sample number is less than 100, then it does not split and the node will become a leaf\n",
    "# random_state set to 1 results in a fixed dataset/will produce the same split\n",
    "rf_model = RandomForestClassifier(n_estimators = 100, min_samples_split = 100, random_state = 1)\n",
    "\n",
    "# train_set contains all values up until the last 100, test_set is the last 100 values\n",
    "train_set = amazon.iloc[:-100]\n",
    "test_set = amazon.iloc[-100:]\n",
    "\n",
    "# define independent/predictor columns\n",
    "predictor_columns = [\"Close\", \"Volume\", \"Open\", \"High\", \"Low\"]\n",
    "\n",
    "# .fit() method is the training part of the model & finds the coefficients for the equation via the algorithm being used (in our case, Random Forest)\n",
    "rf_model.fit(train_set[predictor_columns], train_set[\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prediction function that will train the model on our training set and then make predictions on our testing set\n",
    "\n",
    "# this bit trains our model on our training set\n",
    "def predict_func(train_set, test_set, predictor_columns, rf_model):\n",
    "    rf_model.fit(train_set[predictor_columns], train_set[\"Target\"])\n",
    "\n",
    "# create variable that contains the predictions on our test set\n",
    "    predictions_test = rf_model.predict(test_set[predictor_columns])\n",
    "\n",
    "# then change variable to a dataframe series\n",
    "    predictions_test = pd.Series(predictions_test, index = test_set.index, name = \"Predictions\")\n",
    "\n",
    "# then combine the actual target values and the predicted values from the above dataframe\n",
    "    combine_target_predictions = pd.concat([test_set[\"Target\"], predictions_test], axis = 1)\n",
    "\n",
    "    return combine_target_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a backtesting function, that creates a rolling analysis\n",
    "# e.g. if we have 10 years of data, this will be used to predict the 11th year. Then the 11 years of data will be used to predict the 12th year, and so forth.\n",
    "\n",
    "def backtest_func(data, rf_model, predictor_columns, start = 2500, step = 250):\n",
    "    predictions_result = []\n",
    "\n",
    "    for i in range(start, data.shape[0], step):\n",
    "        train_set = data.iloc[0:i].copy()\n",
    "        test_set = data.iloc[i:(i+step)].copy()\n",
    "\n",
    "        predictions = predict_func(train_set, test_set, predictor_columns, rf_model)\n",
    "\n",
    "        predictions_result.append(predictions)\n",
    "\n",
    "        return pd.concat(predictions_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store our backtest function in the predictions variable.\n",
    "predictions = backtest_func(amazon, rf_model, predictor_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6190476190476191"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use prediction_score module from sklearn.metrics, which gives us a score of observations that were correctly predicted in our model\n",
    "# the result is 0.62, which is OK but can be improved\n",
    "\n",
    "precision_score(predictions[\"Target\"], predictions[\"Predictions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators=50, min_samples_split=2, Precision=0.5357142857142857\n",
      "n_estimators=50, min_samples_split=5, Precision=0.5535714285714286\n",
      "n_estimators=50, min_samples_split=10, Precision=0.576271186440678\n",
      "n_estimators=100, min_samples_split=2, Precision=0.5185185185185185\n",
      "n_estimators=100, min_samples_split=5, Precision=0.5471698113207547\n",
      "n_estimators=100, min_samples_split=10, Precision=0.576271186440678\n",
      "n_estimators=200, min_samples_split=2, Precision=0.5645161290322581\n",
      "n_estimators=200, min_samples_split=5, Precision=0.5689655172413793\n",
      "n_estimators=200, min_samples_split=10, Precision=0.5737704918032787\n"
     ]
    }
   ],
   "source": [
    "# we can try experimenting with different n_estimator_values and min_samples_split_values, to see if the precision_score improves\n",
    "\n",
    "n_estimators_values = [50, 100, 200]\n",
    "min_samples_split_values = [2, 5, 10]\n",
    "\n",
    "# now iterate over different combinations\n",
    "for n_estimators in n_estimators_values:\n",
    "    for min_samples_split in min_samples_split_values:\n",
    "\n",
    "        # create and train the Random Forest model\n",
    "        rf_model = RandomForestClassifier(n_estimators=n_estimators, min_samples_split=min_samples_split, random_state=1)\n",
    "        rf_model.fit(train_set[predictor_columns], train_set[\"Target\"])\n",
    "        \n",
    "        # create predictio and precision variables again\n",
    "        predictions = predict_func(train_set, test_set, predictor_columns, rf_model)\n",
    "        precision = precision_score(predictions[\"Target\"], predictions[\"Predictions\"])\n",
    "        \n",
    "        # Print the results\n",
    "        print(f'n_estimators={n_estimators}, min_samples_split={min_samples_split}, Precision={precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that these results are in fact worse than the previous result, but we can try alternative values/combinations to see if there's improvement\n",
    "# furthermore, we can further try to improve the model through, for example, using feature engineering, or even other algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
